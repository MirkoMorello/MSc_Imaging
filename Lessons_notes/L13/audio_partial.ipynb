{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf2062",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms, utils, models, ops\n",
    "from multiprocessing import cpu_count, Pool\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec43d4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a pytorch dataset class\n",
    "class AudioDataset(data.Dataset):\n",
    "    def __init__(self, root_dir, csv, sets, ms=3000):\n",
    "        # save attributes\n",
    "        self.root_dir = root_dir\n",
    "        self.ms = ms\n",
    "        # TODO: compute number of samples corresponding to self.ms milliseconds\n",
    "        # Consider that that audio files have a sampling rate of 16000 Hz\n",
    "        self.n_samples = \n",
    "        # read csv file\n",
    "        self.df = pd.read_csv(csv)\n",
    "        # keep only the sets we are interested in\n",
    "        self.df = self.df[self.df['fold'].isin(sets)]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get filename and label\n",
    "        filename = self.df.iloc[index]['filename']\n",
    "        label = self.df.iloc[index]['target']\n",
    "        # TODO: load audio file with librosa\n",
    "\n",
    "        # convert to mono if needed\n",
    "        if len(y.shape) > 1:\n",
    "            y = librosa.to_mono(y)\n",
    "        # resample to 16000 Hz\n",
    "        if sr != 16000:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        # replicate if audio is too short\n",
    "        if len(y) < self.n_samples:\n",
    "            y = np.tile(y, self.n_samples // len(y) + 1)\n",
    "        # TODO: random crop to self.n_samples\n",
    "\n",
    "        # TODO: compute win_length and hop_length for mfcc\n",
    "        # - winlength=30ms\n",
    "        # - hoplength=15ms\n",
    "        # note: winlength and hoplength are expressed in milliseconds\n",
    "\n",
    "        # TODO: compute 40 MFCCs with previous parameters (n_mfcc=40)\n",
    "\n",
    "        # return features and label\n",
    "        return mfcc, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test the dataset class\n",
    "ds = AudioDataset('.', 'meta/esc50.csv', [1,2,3,4,5])\n",
    "\n",
    "mfcc, label = ds.__getitem__(0)\n",
    "print(mfcc.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523a063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
