{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from IPython.core.debugger import Tracer\n",
    "import multiprocessing\n",
    "\n",
    "#multiprocessing.set_start_method('spawn')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "learning_rate = 0.01\n",
    "batch_size = 159980\n",
    "experiment_name = 'uber'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, csv):\n",
    "        # super(Dataset, self).__init__()\n",
    "        # read the csv file\n",
    "        self.df = pd.read_csv(csv, sep=r'\\s+')\n",
    "        # self.df = self.df.dropna(axis=0)\n",
    "        # save cols\n",
    "        self.input_cols = ['pickup_longitude', 'pickup_latitude',\n",
    "       'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'year',\n",
    "       'Distance', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5',\n",
    "       'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11',\n",
    "       'month_12', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3',\n",
    "       'weekday_4', 'weekday_5', 'weekday_6', 'hour_0', 'hour_1', 'hour_2',\n",
    "       'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9',\n",
    "       'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15',\n",
    "       'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21',\n",
    "       'hour_22', 'hour_23']\n",
    "        self.output_cols = ['fare_amount']\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: here i will return the number of samples in the dataset\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read row, split in input and output and convert in tensors\n",
    "        cur_sample = self.df.iloc[idx]\n",
    "        # split the current sample in input and output (ground truth)\n",
    "        cur_sample_x = cur_sample[self.input_cols]\n",
    "        cur_sample_y = cur_sample[self.output_cols]\n",
    "        # convert to tensor (torch format)\n",
    "        cur_sample_x = torch.tensor(cur_sample_x.tolist(), dtype=torch.float32)\n",
    "        cur_sample_y = torch.tensor(cur_sample_y.tolist(), dtype=torch.float32)\n",
    "        # return the sample\n",
    "        return cur_sample_x, cur_sample_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# try to use the dataset\n",
    "ds = Dataset('../datasets/Uber/train.csv')\n",
    "# get first item\n",
    "xx,yy = ds.__getitem__(0)\n",
    "# print shapes\n",
    "print(xx.shape)\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation datasets\n",
    "train_ds = Dataset('../datasets/Uber/train.csv')\n",
    "val_ds =  Dataset('../datasets/Uber/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataloader\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size = batch_size,\n",
    "    drop_last = True,\n",
    "    shuffle = False,\n",
    "    num_workers = 8, # this is needed to avoid problems with the multiprocessing since we are using the mps device\n",
    "    # pin_memory=True,\n",
    "    \n",
    ")\n",
    "# create validation dataloader\n",
    "val_dl = torch.utils.data.DataLoader(\n",
    "    val_ds,\n",
    "    batch_size = batch_size,\n",
    "    drop_last = False,\n",
    "    shuffle = False,\n",
    "    num_workers = 8,\n",
    "    #pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define a network composed of linear layers interleaved by ReLUs. Note: last layer must be a linear layer.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call the constructor of the parent class\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # define the layers\n",
    "        self.fc1 = nn.Linear(50, 128) # 13 input features, 128 output features\n",
    "        self.fc2 = nn.Linear(128, 128) \n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 16)\n",
    "        self.fc5 = nn.Linear(16, 1) # 1 output feature\n",
    "        \n",
    "        #self.to('cuda')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # define the forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input shape is torch.Size([2000, 50])\n",
      "Output shape is torch.Size([2000, 1])\n"
     ]
    }
   ],
   "source": [
    "# let's test the network\n",
    "net = Net()\n",
    "\n",
    "# let's move the network in GPU\n",
    "net.to('cuda')\n",
    "\n",
    "# define random batch of 10 elements\n",
    "inp = torch.rand(2000, 50, device=device)\n",
    "\n",
    "# move the batch in GPU\n",
    "# inp = inp.to(device=device)\n",
    "\n",
    "# get the output\n",
    "out = net(inp)\n",
    "\n",
    "# let's print the shape\n",
    "print(' Input shape is', inp.shape)\n",
    "print('Output shape is', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation routine\n",
    "def validate(net, dl):\n",
    "    # get final score\n",
    "    score = 0\n",
    "    # set network in eval mode\n",
    "    net.eval()\n",
    "    # at the end of epoch, validate model\n",
    "    for inp, gt in dl:\n",
    "        # move batch to gpu\n",
    "        inp = inp.to(device)\n",
    "        gt = gt.to(device)\n",
    "        # get output\n",
    "        with torch.no_grad():\n",
    "            out = net(inp)\n",
    "        # compare with gt\n",
    "        cur_score = F.l1_loss(out, gt)\n",
    "        # append\n",
    "        score += cur_score \n",
    "    # at the end, average over batches\n",
    "    score /= len(dl)\n",
    "    # set network in training mode\n",
    "    net.train()\n",
    "    # return score\n",
    "    return score\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir={experiment_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]/tmp/ipykernel_790194/1994136713.py:28: UserWarning: Using a target size (torch.Size([159980])) that is different to the input size (torch.Size([159980, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.l1_loss(out, gt)\n",
      "  0%|          | 0/250 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 95.34 GiB. GPU 0 has a total capacity of 23.45 GiB of which 21.21 GiB is free. Process 702355 has 358.00 MiB memory in use. Including non-PyTorch memory, this process has 602.00 MiB memory in use. Of the allocated memory 245.04 MiB is allocated by PyTorch, and 50.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m out \u001b[38;5;241m=\u001b[39m net(inp)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# compute loss, F1 loss is the mean absolute error\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# backprop\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/functional.py:3309\u001b[0m, in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3306\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m   3308\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[0;32m-> 3309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 95.34 GiB. GPU 0 has a total capacity of 23.45 GiB of which 21.21 GiB is free. Process 702355 has 358.00 MiB memory in use. Including non-PyTorch memory, this process has 602.00 MiB memory in use. Of the allocated memory 245.04 MiB is allocated by PyTorch, and 50.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate)\n",
    "\n",
    "# define summary writer\n",
    "writer = SummaryWriter(experiment_name)\n",
    "\n",
    "# initialize iteration number\n",
    "n_iter = 0\n",
    "\n",
    "# define best validation value\n",
    "best_val = None\n",
    "net.to(device = 'cuda:0')\n",
    "\n",
    "# for each epoch\n",
    "for cur_epoch in tqdm(range(250)):\n",
    "    # plot current epoch\n",
    "    writer.add_scalar(\"epoch\", cur_epoch, n_iter)\n",
    "    # TODO: for every batch, compute output, loss, perform backward propagation and finally update weights\n",
    "    for inp, gt in train_dl:\n",
    "        inp = inp.to(device)\n",
    "        gt = gt.to(device)\n",
    "        # zero gradients (empty the gradient buffer)\n",
    "        optimizer.zero_grad()\n",
    "        # get output\n",
    "        out = net(inp)\n",
    "        # compute loss, F1 loss is the mean absolute error\n",
    "        loss = F.l1_loss(out, gt)\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        # update weights, I do the step, the NN is updated\n",
    "        optimizer.step()\n",
    "        # plot loss\n",
    "        writer.add_scalar(\"train\", loss.item(), n_iter)\n",
    "        # increment iteration number\n",
    "        n_iter += 1\n",
    "        \n",
    "    # at the end, validate model\n",
    "    cur_val = validate(net, val_dl)\n",
    "    # plot validation\n",
    "    writer.add_scalar(\"val\", loss.item(), n_iter)\n",
    "    # TODO: check if it is the best model so far\n",
    "    if best_val is None or cur_val > best_val:\n",
    "        data = {\n",
    "            'data' : net.state_dict(),\n",
    "            'opt' : optimizer.state_dict(),\n",
    "            'epoch' : cur_epoch}\n",
    "        \n",
    "        torch.save(data, experiment_name + '_best.pth')\n",
    "        # update best validation value\n",
    "        best_val = cur_val\n",
    "    # save optimizer\n",
    "    data = {\n",
    "        'data' : net.state_dict(),\n",
    "        'opt' : optimizer.state_dict(),\n",
    "        'epoch' : cur_epoch}\n",
    "    torch.save(optimizer.state_dict(), '_last.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
