{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L07 05/04/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3, classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omirako/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-02 22:56:04.146539: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 22:56:04.809458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the heat generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Override Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv):\n",
    "        df = pd.read_csv(csv, sep=r',')\n",
    "        df.Cover_Type = df.Cover_Type - 1 # this is needed, classes must start from 0\n",
    "        self.data = torch.tensor(df.drop(columns=['Cover_Type']).values, dtype=torch.float32) # viene messo in memoria, non si pu√≤ fare con dataset molto grandi\n",
    "        self.target = torch.tensor(df.Cover_Type.values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(54, 128) # 50 input features\n",
    "        self.fc2 = nn.Linear(128, 128) \n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 16)\n",
    "        self.fc5 = nn.Linear(16, 7) # 1 output feature\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def validate_with_loss(model, val_loader):\n",
    "    # Validate classification model:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    acc_micro = torchmetrics.Accuracy(task = 'multiclass', num_classes = 7, average = 'micro').to(device)\n",
    "    acc_macro = torchmetrics.Accuracy(task = 'multiclass', num_classes = 7, average = 'macro').to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)  # Compute cross-entropy loss\n",
    "            total_loss += loss.item() * inputs.size(0)  # Multiply by batch size to account for different batch sizes\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            print('pred:', predicted)\n",
    "            print('outputs:', labels)\n",
    "            acc_micro.update(predicted, labels)\n",
    "            acc_macro.update(predicted, labels)\n",
    "            total_loss += loss.item()\n",
    "    return acc_micro.compute(), acc_macro.compute(), total_loss / len(val_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.367095</td>\n",
       "      <td>-0.959980</td>\n",
       "      <td>-1.597132</td>\n",
       "      <td>0.146639</td>\n",
       "      <td>-0.834074</td>\n",
       "      <td>-0.908681</td>\n",
       "      <td>0.271454</td>\n",
       "      <td>0.571653</td>\n",
       "      <td>0.281259</td>\n",
       "      <td>4.334805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.608916</td>\n",
       "      <td>-0.959980</td>\n",
       "      <td>-1.123963</td>\n",
       "      <td>-0.881597</td>\n",
       "      <td>-0.801414</td>\n",
       "      <td>-0.726043</td>\n",
       "      <td>0.369620</td>\n",
       "      <td>0.264652</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>3.695656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.570608</td>\n",
       "      <td>-0.932727</td>\n",
       "      <td>-1.005671</td>\n",
       "      <td>-0.491248</td>\n",
       "      <td>-0.834074</td>\n",
       "      <td>-0.812079</td>\n",
       "      <td>0.402343</td>\n",
       "      <td>0.133080</td>\n",
       "      <td>-0.110952</td>\n",
       "      <td>3.689292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.024715</td>\n",
       "      <td>-0.360428</td>\n",
       "      <td>0.887003</td>\n",
       "      <td>-0.476967</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>1.182604</td>\n",
       "      <td>1.318565</td>\n",
       "      <td>-0.393208</td>\n",
       "      <td>-1.396532</td>\n",
       "      <td>4.111148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.544271</td>\n",
       "      <td>-0.469437</td>\n",
       "      <td>-1.123963</td>\n",
       "      <td>-0.510290</td>\n",
       "      <td>-0.817744</td>\n",
       "      <td>-0.844531</td>\n",
       "      <td>0.664120</td>\n",
       "      <td>0.527796</td>\n",
       "      <td>-0.110952</td>\n",
       "      <td>3.689292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>-0.278507</td>\n",
       "      <td>-0.360428</td>\n",
       "      <td>-1.597132</td>\n",
       "      <td>0.237086</td>\n",
       "      <td>-0.360507</td>\n",
       "      <td>0.089792</td>\n",
       "      <td>0.402343</td>\n",
       "      <td>0.747083</td>\n",
       "      <td>0.237680</td>\n",
       "      <td>-0.687469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>-0.759755</td>\n",
       "      <td>-0.178745</td>\n",
       "      <td>-0.769087</td>\n",
       "      <td>-0.938722</td>\n",
       "      <td>-0.981043</td>\n",
       "      <td>0.128282</td>\n",
       "      <td>0.762287</td>\n",
       "      <td>0.747083</td>\n",
       "      <td>-0.110952</td>\n",
       "      <td>-1.141147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>-0.714264</td>\n",
       "      <td>1.465481</td>\n",
       "      <td>-0.295918</td>\n",
       "      <td>-0.124701</td>\n",
       "      <td>-0.017579</td>\n",
       "      <td>-0.655855</td>\n",
       "      <td>-0.939268</td>\n",
       "      <td>0.352367</td>\n",
       "      <td>1.043891</td>\n",
       "      <td>-0.396534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>-0.726235</td>\n",
       "      <td>-1.050821</td>\n",
       "      <td>1.241880</td>\n",
       "      <td>-0.762588</td>\n",
       "      <td>-0.605456</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>-0.023046</td>\n",
       "      <td>-2.147500</td>\n",
       "      <td>-1.244006</td>\n",
       "      <td>-1.130237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>-0.790880</td>\n",
       "      <td>0.420807</td>\n",
       "      <td>0.413835</td>\n",
       "      <td>-0.795911</td>\n",
       "      <td>-0.638115</td>\n",
       "      <td>-0.382653</td>\n",
       "      <td>-0.219380</td>\n",
       "      <td>1.492657</td>\n",
       "      <td>0.869575</td>\n",
       "      <td>-0.473813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218671</td>\n",
       "      <td>-0.206085</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.047474</td>\n",
       "      <td>-0.224908</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>-0.176939</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512 rows √ó 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     -0.367095 -0.959980 -1.597132                          0.146639   \n",
       "1     -0.608916 -0.959980 -1.123963                         -0.881597   \n",
       "2     -0.570608 -0.932727 -1.005671                         -0.491248   \n",
       "3     -0.024715 -0.360428  0.887003                         -0.476967   \n",
       "4     -0.544271 -0.469437 -1.123963                         -0.510290   \n",
       "...         ...       ...       ...                               ...   \n",
       "1507  -0.278507 -0.360428 -1.597132                          0.237086   \n",
       "1508  -0.759755 -0.178745 -0.769087                         -0.938722   \n",
       "1509  -0.714264  1.465481 -0.295918                         -0.124701   \n",
       "1510  -0.726235 -1.050821  1.241880                         -0.762588   \n",
       "1511  -0.790880  0.420807  0.413835                         -0.795911   \n",
       "\n",
       "      Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                          -0.834074                        -0.908681   \n",
       "1                          -0.801414                        -0.726043   \n",
       "2                          -0.834074                        -0.812079   \n",
       "3                           0.031410                         1.182604   \n",
       "4                          -0.817744                        -0.844531   \n",
       "...                              ...                              ...   \n",
       "1507                       -0.360507                         0.089792   \n",
       "1508                       -0.981043                         0.128282   \n",
       "1509                       -0.017579                        -0.655855   \n",
       "1510                       -0.605456                         0.003756   \n",
       "1511                       -0.638115                        -0.382653   \n",
       "\n",
       "      Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          0.271454        0.571653       0.281259   \n",
       "1          0.369620        0.264652       0.041574   \n",
       "2          0.402343        0.133080      -0.110952   \n",
       "3          1.318565       -0.393208      -1.396532   \n",
       "4          0.664120        0.527796      -0.110952   \n",
       "...             ...             ...            ...   \n",
       "1507       0.402343        0.747083       0.237680   \n",
       "1508       0.762287        0.747083      -0.110952   \n",
       "1509      -0.939268        0.352367       1.043891   \n",
       "1510      -0.023046       -2.147500      -1.244006   \n",
       "1511      -0.219380        1.492657       0.869575   \n",
       "\n",
       "      Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                               4.334805  ...    -0.218671    -0.206085   \n",
       "1                               3.695656  ...    -0.218671    -0.206085   \n",
       "2                               3.689292  ...    -0.218671    -0.206085   \n",
       "3                               4.111148  ...    -0.218671    -0.206085   \n",
       "4                               3.689292  ...    -0.218671    -0.206085   \n",
       "...                                  ...  ...          ...          ...   \n",
       "1507                           -0.687469  ...    -0.218671    -0.206085   \n",
       "1508                           -1.141147  ...    -0.218671    -0.206085   \n",
       "1509                           -0.396534  ...    -0.218671    -0.206085   \n",
       "1510                           -1.130237  ...    -0.218671    -0.206085   \n",
       "1511                           -0.473813  ...    -0.218671    -0.206085   \n",
       "\n",
       "      Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0       -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "1       -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "2       -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "3       -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "4       -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1507    -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "1508    -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "1509    -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "1510    -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "1511    -0.038173    -0.082413    -0.025726    -0.047474    -0.224908   \n",
       "\n",
       "      Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0       -0.213134    -0.176939           5  \n",
       "1       -0.213134    -0.176939           5  \n",
       "2       -0.213134    -0.176939           5  \n",
       "3       -0.213134    -0.176939           5  \n",
       "4       -0.213134    -0.176939           5  \n",
       "...           ...          ...         ...  \n",
       "1507    -0.213134    -0.176939           3  \n",
       "1508    -0.213134    -0.176939           6  \n",
       "1509    -0.213134    -0.176939           6  \n",
       "1510    -0.213134    -0.176939           3  \n",
       "1511    -0.213134    -0.176939           3  \n",
       "\n",
       "[1512 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/ForestDataset/val.csv', sep=r',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "batch_size = 1512\n",
    "epochs = 2500\n",
    "num_workers = 2\n",
    "n_iter = 0\n",
    "\n",
    "\n",
    "train_dataset = Dataset('../datasets/ForestDataset/train.csv')\n",
    "val_dataset = Dataset('../datasets/ForestDataset/val.csv')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "writer = SummaryWriter('Forest_experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bbb3eaff3b82a01\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bbb3eaff3b82a01\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir={experiment_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2500 [00:00<02:14, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2500 [00:00<02:37, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2500 [00:00<02:12, 18.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2500 [00:00<02:32, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([1, 1, 4,  ..., 2, 5, 2], device='cuda:0')\n",
      "outputs: tensor([4, 4, 4,  ..., 5, 2, 2], device='cuda:0')\n",
      "pred: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     num_val_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# measure validation loss    \u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     acc_micro, acc_max, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_with_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#    writer.add_scalar(\"val_loss\", val_loss, n_iter)  # Add validation loss to tensorboard\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#    print(f'Validation Acc Micro: {acc_micro}, Acc Macro: {acc_max}')\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, acc_micro, n_iter)\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36mvalidate_with_loss\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m     15\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Multiply by batch size to account for different batch sizes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs:\u001b[39m\u001b[38;5;124m'\u001b[39m, labels)\n\u001b[1;32m     19\u001b[0m acc_micro\u001b[38;5;241m.\u001b[39mupdate(predicted, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor.py:461\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    458\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    459\u001b[0m     )\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor_str.py:677\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    676\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor_str.py:426\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# Note [Print tensor device]:\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# A general logic here is we only print device when it doesn't match\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# the device specified in default tensor type.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# In other cases, we don't have a way to set them as default yet,\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# and we should always print out device for them.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_default_device()\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    425\u001b[0m ):\n\u001b[0;32m--> 426\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Tensor printing performs tensor operations like slice, indexing, etc to make it in a\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# representable format. These operations on ipu/xla/lazy/mtia tensor results in compilations. Hence,\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# to avoid compilations, copying the tensor to cpu before printing.\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlazy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmtia\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "n_iter = 0\n",
    "model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    writer.add_scalar(\"epoch\", epoch, n_iter)\n",
    "    for data, target in train_loader:\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)  # Compute the loss\n",
    "        writer.add_scalar(\"loss\", loss.item(), n_iter)  # Add loss to tensorboard\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_iter += 1\n",
    "\n",
    "    val_loss = 0.0\n",
    "    num_val_samples = 0\n",
    "    \n",
    "    # measure validation loss    \n",
    "    acc_micro, acc_max, val_loss = validate_with_loss(model, val_loader)\n",
    "    \n",
    "#    writer.add_scalar(\"val_loss\", val_loss, n_iter)  # Add validation loss to tensorboard\n",
    "#    print(f'Validation Acc Micro: {acc_micro}, Acc Macro: {acc_max}')\n",
    "    writer.add_scalar(\"val_acc\", acc_micro, n_iter)\n",
    "    writer.add_scalar(\"val_loss\", val_loss, n_iter)\n",
    "    \n",
    "# set description tqdm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
